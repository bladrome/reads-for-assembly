{
 "metadata": {
  "name": "",
  "signature": "sha256:7faf7e2496a186bf93a855919f991a3bcb6e4b42effaec1c8d2b7c8c711d4297"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "README"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a script to generate short reads from contigs so they can be assembled back. While doing this you can specify a desired average coverage for each entry, and define an expected error rate.\n",
      "\n",
      "Say, you have multiple FASTA files that contain contigs from draft genomes, and you wish to create a single FASTA file that contains enough number of short reads that are randomly created from these files to meet your expected coverage. Here is an example.\n",
      "\n",
      "  _Note: If you would like to run these examples yourself, type _`ipython notebook readme.ipynb`_ in the source directory after cloning it_\n",
      "\n",
      "For a little demonstration I put a `files` directory with 5 FASTAS files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls files/*fa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each FASTA file is sampled from a different bacterial genome, contains 5 contigs that are about 7,500nts long.\n",
      "\n",
      "To generate short reads from this I have this config file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat sample-config.ini"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The config file simply says; \n",
      "\n",
      "> _\"Generage enough __100nt__ long short reads from all entries you find in __sample/fasta_01.fa__, so when I assemble them back, the average coverage would be about __100X__ throughout the contig. Oh, while doing this, introduce random errors to meet __0.05__ error rate in average. In fact do the same for every other entry in this config file with respect to their coverage values, and store all these results in __short_reads.fa__\"_.\n",
      "\n",
      "Once you have your config file ready, this is how you run it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!./gen-short-reads sample-config.ini"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There it is. So in theory, if you assemble short_reads.fa, you should recover contigs that are about 50, 100, 150 and 200X coverage. Just for fun, I used [velvet](https://www.ebi.ac.uk/~zerbino/velvet/) to assemble what is in the short_reads.fa, then used [bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml) to map reads back to resulting contigs, and analyzed the mapping.\n",
      "\n",
      "Here what I did step by step (excuse me for the crudeness of my demo and directly copy-pasting from my command line):\n",
      "\n",
      "    $ mkdir velvet_output/\n",
      "    $ velveth velvet_output/ 17 short_reads.fa\n",
      "    $ velvetg velvet_output/\n",
      "    $ bowtie2-build velvet_output/contigs.fa contigs_ref\n",
      "    $ bowtie2 -f short_reads.fa -x contigs_ref -S output.sam\n",
      "    209000 reads; of these:\n",
      "      209000 (100.00%) were unpaired; of these:\n",
      "        4070 (1.95%) aligned 0 times\n",
      "        204930 (98.05%) aligned exactly 1 time\n",
      "        0 (0.00%) aligned >1 times\n",
      "    98.05% overall alignment rate\n",
      "    $ samtools view -bS output.sam > output.bam\n",
      "\n",
      "I further analyzed the BAM file in an _ad hoc_ manner with in-house scripts. Here is the average coverage of each contig in `output.bam` file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import Image\n",
      "Image(filename=\"files/average_coverage.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So randomly generated and assembled short reads did creaete expected coverage profiles.\n",
      "\n",
      "Here is the detailed coverage of one of those contigs that is at 50X coverage:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import Image\n",
      "Image(filename=\"files/50X.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And another example from a contig that is covered about 200X:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import Image\n",
      "Image(filename=\"files/200X.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is indeed going to be useful for my purposes, but I would like it to be useful to you as well. So if this is what you need to do benchmarks or to test your stuff, and if its missing something for your purposes, please don't hesitate to get in touch with [me](http://meren.org)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}